{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average duration and number of runs\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "from pyproj import Transformer\n",
    "from shapely import wkt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "file_paths = [\n",
    "    'new_cleaned/november_traffic.parquet',\n",
    "    'new_cleaned/october_traffic.parquet',\n",
    "    'new_cleaned/december_traffic.parquet',\n",
    "    'new_cleaned/january_traffic.parquet',\n",
    "    'new_cleaned/february_traffic.parquet',\n",
    "    'new_cleaned/march_traffic.parquet',\n",
    "    'new_cleaned/april_traffic.parquet'\n",
    "    # Add paths for all the months you have\n",
    "]\n",
    "\n",
    "# Load all runs data into a single GeoDataFrame\n",
    "runs_list = [gpd.read_parquet(file_path) for file_path in file_paths]\n",
    "runs = pd.concat(runs_list, ignore_index=True)\n",
    "\n",
    "# Reset index to ensure clean, sequential indices before processing\n",
    "runs.reset_index()\n",
    "\n",
    "# Calculate the total number of unique runs in the GeoDataFrame\n",
    "total_runs = runs['run'].nunique()\n",
    "\n",
    "print(f'Total number of unique runs: {total_runs}')\n",
    "\n",
    "# Convert utcTime to datetime\n",
    "runs['utcTime'] = pd.to_datetime(runs['utcTime'])\n",
    "\n",
    "# Check and convert geometry column if necessary\n",
    "if isinstance(runs['geometry'].iloc[0], str):\n",
    "    runs['geometry'] = runs['geometry'].apply(wkt.loads)\n",
    "\n",
    "# Define a transformer from UTM Zone 32N to WGS 84 (latitude and longitude)\n",
    "transformer = Transformer.from_crs(\"epsg:32632\", \"epsg:4326\", always_xy=True)\n",
    "\n",
    "# Apply transformation to convert coordinates\n",
    "runs['longitude'], runs['latitude'] = transformer.transform(runs['geometry'].x, runs['geometry'].y)\n",
    "\n",
    "# Group by 'run' and calculate start and end times for each run\n",
    "run_durations = runs.groupby('run').agg(\n",
    "    start_time=('utcTime', 'first'),  # Get the first timestamp for each run\n",
    "    end_time=('utcTime', 'last'),     # Get the last timestamp for each run\n",
    "    start_latitude=('latitude', 'first'),  # Get the first latitude for each run\n",
    "    start_longitude=('longitude', 'first')  # Get the first longitude for each run\n",
    ")\n",
    "\n",
    "# Calculate the duration of each run in seconds\n",
    "run_durations['duration'] = (run_durations['end_time'] - run_durations['start_time']).dt.total_seconds()\n",
    "\n",
    "# Reset the index to make 'run' a column\n",
    "run_durations.reset_index(inplace=True)\n",
    "\n",
    "# Extract the hour from the start_time for visualization\n",
    "run_durations['start_hour'] = run_durations['start_time'].dt.hour\n",
    "\n",
    "# Calculate the average duration for each hour\n",
    "avg_duration_per_hour = run_durations.groupby('start_hour')['duration'].mean().reset_index()\n",
    "\n",
    "# Calculate the number of runs for each hour\n",
    "num_runs_per_hour = run_durations.groupby('start_hour').size().reset_index(name='num_runs')\n",
    "\n",
    "# Merge the average duration and number of runs dataframes\n",
    "merged_hour_data = pd.merge(avg_duration_per_hour, num_runs_per_hour, on='start_hour')\n",
    "\n",
    "# Extract week and year information using dt.isocalendar()\n",
    "run_durations['year'] = run_durations['start_time'].dt.isocalendar().year\n",
    "run_durations['week'] = run_durations['start_time'].dt.isocalendar().week\n",
    "\n",
    "# Create a new column to uniquely identify each week in each year\n",
    "run_durations['year_week'] = run_durations['year'].astype(str) + '-W' + run_durations['week'].astype(str)\n",
    "\n",
    "# Group by the new 'year_week' column\n",
    "avg_duration_per_week = run_durations.groupby('year_week')['duration'].mean().reset_index()\n",
    "num_runs_per_week = run_durations.groupby('year_week').size().reset_index(name='num_runs')\n",
    "\n",
    "# Merge the average duration and number of runs dataframes for weeks\n",
    "merged_week_data = pd.merge(avg_duration_per_week, num_runs_per_week, on='year_week')\n",
    "\n",
    "# Extract month and year information\n",
    "run_durations['year_month'] = run_durations['start_time'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Group by the new 'year_month' column\n",
    "avg_duration_per_month = run_durations.groupby('year_month')['duration'].mean().reset_index()\n",
    "num_runs_per_month = run_durations.groupby('year_month').size().reset_index(name='num_runs')\n",
    "\n",
    "# Merge the average duration and number of runs dataframes for months\n",
    "merged_month_data = pd.merge(avg_duration_per_month, num_runs_per_month, on='year_month')\n",
    "\n",
    "# Extract day of week information\n",
    "run_durations['day_of_week'] = run_durations['start_time'].dt.dayofweek\n",
    "\n",
    "# Map day of week number to day name\n",
    "day_name_mapping = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\n",
    "run_durations['day_name'] = run_durations['day_of_week'].map(day_name_mapping)\n",
    "\n",
    "# Group by the day of the week\n",
    "avg_duration_per_day = run_durations.groupby('day_name')['duration'].mean().reset_index()\n",
    "num_runs_per_day = run_durations.groupby('day_name').size().reset_index(name='num_runs')\n",
    "\n",
    "# Merge the average duration and number of runs dataframes for days of the week\n",
    "merged_day_data = pd.merge(avg_duration_per_day, num_runs_per_day, on='day_name')\n",
    "\n",
    "# Sort by day of week for correct order in the plot\n",
    "merged_day_data['day_of_week'] = merged_day_data['day_name'].map({v: k for k, v in day_name_mapping.items()})\n",
    "merged_day_data.sort_values('day_of_week', inplace=True)\n",
    "\n",
    "# Plot average duration and number of runs per hour\n",
    "fig_hour = go.Figure()\n",
    "\n",
    "# Add the average duration line (red)\n",
    "fig_hour.add_trace(go.Scatter(\n",
    "    x=merged_hour_data['start_hour'], \n",
    "    y=merged_hour_data['duration'], \n",
    "    mode='lines+markers+text',\n",
    "    text=merged_hour_data['num_runs'],\n",
    "    textposition='top center',\n",
    "    name='Average Duration (seconds)',\n",
    "    line=dict(color='red')\n",
    "))\n",
    "\n",
    "# Add a note in the corner\n",
    "fig_hour.add_annotation(\n",
    "    xref='paper', yref='paper',\n",
    "    x=0.95, y=0.95,\n",
    "    text='Number of runs',\n",
    "    showarrow=False\n",
    ")\n",
    "\n",
    "fig_hour.update_layout(\n",
    "    title='Average Run Duration and Number of Runs Compared to Time of Day',\n",
    "    xaxis=dict(title='Hour of Day'),\n",
    "    yaxis=dict(\n",
    "        title='Average Duration (seconds)',\n",
    "    ),\n",
    "    legend=dict(x=0.1, y=1.1)\n",
    ")\n",
    "\n",
    "# Plot average duration and number of runs per week\n",
    "fig_week = go.Figure()\n",
    "\n",
    "# Add the average duration line (red)\n",
    "fig_week.add_trace(go.Scatter(\n",
    "    x=merged_week_data['year_week'], \n",
    "    y=merged_week_data['duration'], \n",
    "    mode='lines+markers+text',\n",
    "    text=merged_week_data['num_runs'],\n",
    "    textposition='top center',\n",
    "    name='Average Duration (seconds)',\n",
    "    line=dict(color='red')\n",
    "))\n",
    "\n",
    "# Add a note in the corner\n",
    "fig_week.add_annotation(\n",
    "    xref='paper', yref='paper',\n",
    "    x=0.95, y=0.95,\n",
    "    text='Number of runs',\n",
    "    showarrow=False\n",
    ")\n",
    "\n",
    "fig_week.update_layout(\n",
    "    title='Average Run Duration and Number of Runs Per Week',\n",
    "    xaxis=dict(title='Week', tickmode='linear'),\n",
    "    yaxis=dict(\n",
    "        title='Average Duration (seconds)',\n",
    "    ),\n",
    "    legend=dict(x=0.1, y=1.1)\n",
    ")\n",
    "\n",
    "# Plot average duration and number of runs per month\n",
    "fig_month = go.Figure()\n",
    "\n",
    "# Add the average duration line (red)\n",
    "fig_month.add_trace(go.Scatter(\n",
    "    x=merged_month_data['year_month'], \n",
    "    y=merged_month_data['duration'], \n",
    "    mode='lines+markers+text',\n",
    "    text=merged_month_data['num_runs'],\n",
    "    textposition='top center',\n",
    "    name='Average Duration (seconds)',\n",
    "    line=dict(color='red')\n",
    "))\n",
    "\n",
    "# Add a note in the corner\n",
    "fig_month.add_annotation(\n",
    "    xref='paper', yref='paper',\n",
    "    x=0.95, y=0.95,\n",
    "    text='Number of runs',\n",
    "    showarrow=False\n",
    ")\n",
    "\n",
    "fig_month.update_layout(\n",
    "    title='Average Run Duration and Number of Runs Per Month',\n",
    "    xaxis=dict(title='Month'),\n",
    "    yaxis=dict(\n",
    "        title='Average Duration (seconds)',\n",
    "    ),\n",
    "    legend=dict(x=0.1, y=1.1)\n",
    ")\n",
    "\n",
    "# Plot average duration and number of runs per day of the week\n",
    "fig_day = go.Figure()\n",
    "\n",
    "# Add the average duration line (red)\n",
    "fig_day.add_trace(go.Scatter(\n",
    "    x=merged_day_data['day_name'], \n",
    "    y=merged_day_data['duration'], \n",
    "    mode='lines+markers+text',\n",
    "    text=merged_day_data['num_runs'],\n",
    "    textposition='top center',\n",
    "    name='Average Duration (seconds)',\n",
    "    line=dict(color='red')\n",
    "))\n",
    "\n",
    "# Add a note in the corner\n",
    "fig_day.add_annotation(\n",
    "    xref='paper', yref='paper',\n",
    "    x=0.95, y=0.95,\n",
    "    text='Number of runs',\n",
    "    showarrow=False\n",
    ")\n",
    "\n",
    "fig_day.update_layout(\n",
    "    title='Average Run Duration and Number of Runs Per Day of the Week',\n",
    "    xaxis=dict(title='Day of Week'),\n",
    "    yaxis=dict(\n",
    "        title='Average Duration (seconds)',\n",
    "    ),\n",
    "    legend=dict(x=0.1, y=1.1)\n",
    ")\n",
    "\n",
    "# Show the plots\n",
    "fig_hour.show()\n",
    "fig_week.show()\n",
    "fig_month.show()\n",
    "fig_day.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average (mean) duration\n",
    "average_duration = run_durations['duration'].mean()\n",
    "\n",
    "# Calculate the range of durations (max - min)\n",
    "range_duration = run_durations['duration'].max() - run_durations['duration'].min()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average Duration: {average_duration} seconds\")\n",
    "print(f\"Range of Durations: {range_duration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "from pyproj import Transformer\n",
    "from shapely import wkt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "file_paths = [\n",
    "    'Data/gdf_23-11-01_23-12-01.parquet',\n",
    "    'Data/gdf_23-10-01_23-11-01.parquet',\n",
    "    'Data/gdf_23-12-01_24-01-01.parquet',\n",
    "    'Data/gdf_24-01-01_24-02-01.parquet',\n",
    "    'Data/gdf_24-02-01_24-03-01.parquet',\n",
    "    'Data/gdf_24-03-01_24-04-01.parquet',\n",
    "    'Data/gdf_24-04-01_24-04-22.parquet'\n",
    "    # Add paths for all the months you have\n",
    "]\n",
    "\n",
    "# Load all runs data into a single GeoDataFrame\n",
    "runs_list = [gpd.read_parquet(file_path) for file_path in file_paths]\n",
    "runs = pd.concat(runs_list)\n",
    "total_runs = runs.index.get_level_values('run').nunique()\n",
    "\n",
    "print(f'Total number of unique runs: {total_runs}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution plots\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "from pyproj import Transformer\n",
    "from shapely import wkt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "file_paths = [\n",
    "    'new_cleaned/cleaned_november.parquet',\n",
    "    'new_cleaned/cleaned_october.parquet',\n",
    "    'new_cleaned/cleaned_december.parquet',\n",
    "    'new_cleaned/cleaned_january.parquet',\n",
    "    'new_cleaned/cleaned_february.parquet',\n",
    "    'new_cleaned/cleaned_march.parquet',\n",
    "    'new_cleaned/cleaned_april.parquet'\n",
    "    # Add paths for all the months you have\n",
    "]\n",
    "\n",
    "# Load all runs data into a single GeoDataFrame\n",
    "runs_list = [gpd.read_parquet(file_path) for file_path in file_paths]\n",
    "runs = pd.concat(runs_list, ignore_index=True)\n",
    "\n",
    "# Reset index to ensure clean, sequential indices before processing\n",
    "runs.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Calculate the total number of unique runs in the GeoDataFrame\n",
    "total_runs = runs['run'].nunique()\n",
    "\n",
    "print(f'Total number of unique runs: {total_runs}')\n",
    "\n",
    "# Convert utcTime to datetime\n",
    "runs['utcTime'] = pd.to_datetime(runs['utcTime'])\n",
    "\n",
    "# Check and convert geometry column if necessary\n",
    "if isinstance(runs['geometry'].iloc[0], str):\n",
    "    runs['geometry'] = runs['geometry'].apply(wkt.loads)\n",
    "\n",
    "# Define a transformer from UTM Zone 32N to WGS 84 (latitude and longitude)\n",
    "transformer = Transformer.from_crs(\"epsg:32632\", \"epsg:4326\", always_xy=True)\n",
    "\n",
    "# Apply transformation to convert coordinates\n",
    "runs['longitude'], runs['latitude'] = transformer.transform(runs['geometry'].x, runs['geometry'].y)\n",
    "\n",
    "# Group by 'run' and calculate start and end times for each run\n",
    "run_durations = runs.groupby('run').agg(\n",
    "    start_time=('utcTime', 'first'),  # Get the first timestamp for each run\n",
    "    end_time=('utcTime', 'last'),     # Get the last timestamp for each run\n",
    "    start_latitude=('latitude', 'first'),  # Get the first latitude for each run\n",
    "    start_longitude=('longitude', 'first')  # Get the first longitude for each run\n",
    ")\n",
    "\n",
    "# Calculate the duration of each run in seconds\n",
    "run_durations['duration'] = (run_durations['end_time'] - run_durations['start_time']).dt.total_seconds()\n",
    "\n",
    "# Reset the index to make 'run' a column\n",
    "run_durations.reset_index(inplace=True)\n",
    "\n",
    "# Extract the hour from the start_time for visualization\n",
    "run_durations['start_hour'] = run_durations['start_time'].dt.hour\n",
    "\n",
    "# Extract the day of the week from the start_time for visualization\n",
    "run_durations['start_day'] = run_durations['start_time'].dt.dayofweek\n",
    "\n",
    "# Extract week and year information using dt.isocalendar()\n",
    "run_durations['year'] = run_durations['start_time'].dt.isocalendar().year\n",
    "run_durations['week'] = run_durations['start_time'].dt.isocalendar().week\n",
    "\n",
    "# Create a new column to uniquely identify each week in each year\n",
    "run_durations['year_week'] = run_durations['year'].astype(str) + '-W' + run_durations['week'].astype(str)\n",
    "\n",
    "# Extract month and year information\n",
    "run_durations['year_month'] = run_durations['start_time'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Day of week mapping\n",
    "day_names = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\n",
    "run_durations['start_day_name'] = run_durations['start_day'].map(day_names)\n",
    "\n",
    "# Plot duration distribution per hour\n",
    "fig_hour_dist = go.Figure()\n",
    "\n",
    "# Add the duration points (scatter)\n",
    "fig_hour_dist.add_trace(go.Scatter(\n",
    "    x=run_durations['start_hour'], \n",
    "    y=run_durations['duration'], \n",
    "    mode='markers',\n",
    "    name='Duration (seconds)',\n",
    "    marker=dict(color='blue', opacity=0.5)\n",
    "))\n",
    "\n",
    "fig_hour_dist.update_layout(\n",
    "    title='Run Duration Distribution by Hour of Day',\n",
    "    xaxis=dict(title='Hour of Day'),\n",
    "    yaxis=dict(\n",
    "        title='Duration (seconds)',\n",
    "    ),\n",
    "    legend=dict(x=0.1, y=1.1)\n",
    ")\n",
    "\n",
    "# Plot duration distribution per week\n",
    "fig_week_dist = go.Figure()\n",
    "\n",
    "# Add the duration points (scatter)\n",
    "fig_week_dist.add_trace(go.Scatter(\n",
    "    x=run_durations['year_week'], \n",
    "    y=run_durations['duration'], \n",
    "    mode='markers',\n",
    "    name='Duration (seconds)',\n",
    "    marker=dict(color='blue', opacity=0.5)\n",
    "))\n",
    "\n",
    "fig_week_dist.update_layout(\n",
    "    title='Run Duration Distribution by Week',\n",
    "    xaxis=dict(title='Week', tickmode='linear'),\n",
    "    yaxis=dict(\n",
    "        title='Duration (seconds)',\n",
    "    ),\n",
    "    legend=dict(x=0.1, y=1.1)\n",
    ")\n",
    "\n",
    "# Plot duration distribution per month\n",
    "fig_month_dist = go.Figure()\n",
    "\n",
    "# Add the duration points (scatter)\n",
    "fig_month_dist.add_trace(go.Scatter(\n",
    "    x=run_durations['year_month'], \n",
    "    y=run_durations['duration'], \n",
    "    mode='markers',\n",
    "    name='Duration (seconds)',\n",
    "    marker=dict(color='blue', opacity=0.5)\n",
    "))\n",
    "\n",
    "fig_month_dist.update_layout(\n",
    "    title='Run Duration Distribution by Month',\n",
    "    xaxis=dict(title='Month'),\n",
    "    yaxis=dict(\n",
    "        title='Duration (seconds)',\n",
    "    ),\n",
    "    legend=dict(x=0.1, y=1.1)\n",
    ")\n",
    "\n",
    "# Plot duration distribution per day of the week\n",
    "fig_day_dist = go.Figure()\n",
    "\n",
    "# Add the duration points (scatter)\n",
    "fig_day_dist.add_trace(go.Scatter(\n",
    "    x=run_durations['start_day_name'], \n",
    "    y=run_durations['duration'], \n",
    "    mode='markers',\n",
    "    name='Duration (seconds)',\n",
    "    marker=dict(color='blue', opacity=0.5)\n",
    "))\n",
    "\n",
    "fig_day_dist.update_layout(\n",
    "    title='Run Duration Distribution by Day of Week',\n",
    "    xaxis=dict(title='Day of Week', tickmode='linear', categoryorder='array', categoryarray=list(day_names.values())),\n",
    "    yaxis=dict(\n",
    "        title='Duration (seconds)',\n",
    "    ),\n",
    "    legend=dict(x=0.1, y=1.1)\n",
    ")\n",
    "\n",
    "# Show the plots\n",
    "fig_hour_dist.show()\n",
    "fig_week_dist.show()\n",
    "fig_month_dist.show()\n",
    "fig_day_dist.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
