{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, LineString\n",
    "from shapely.ops import nearest_points\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from datetime import datetime\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of file paths for each month\n",
    "file_paths = [\n",
    "   'new_cleaned/cleaned_november_without.parquet',\n",
    "   'new_cleaned/cleaned_december_without.parquet',\n",
    "   'new_cleaned/cleaned_January_without.parquet',\n",
    "   'new_cleaned/cleaned_october_without.parquet',\n",
    "   'new_cleaned/cleaned_february_without.parquet',\n",
    "   'new_cleaned/cleaned_march_without.parquet',\n",
    "   'new_cleaned/cleaned_april_without.parquet'\n",
    "    # Add paths for all the months you have\n",
    "]\n",
    "\n",
    "# Load all runs data into a single GeoDataFrame\n",
    "runs_list = [gpd.read_parquet(file_path) for file_path in file_paths]\n",
    "runs = pd.concat(runs_list, ignore_index=True)\n",
    "\n",
    "# Load the stop lines data\n",
    "stop_lines = gpd.read_parquet('Data/stop_lines_cut.parquet')\n",
    "bus_stops = gpd.read_parquet('Data/bus_stops.parquet')\n",
    "\n",
    "\n",
    "# Print the total number of rows\n",
    "print(\"Total number of rows:\", len(runs))\n",
    "\n",
    "# Ensure CRS matches, if not reproject\n",
    "if stop_lines.crs != runs.crs:\n",
    "    stop_lines = stop_lines.to_crs(runs.crs)\n",
    "\n",
    "# Extract the first two unique runs to create the route\n",
    "first_two_runs_ids = runs['run'].unique()[:5]\n",
    "first_two_runs = runs[runs['run'].isin(first_two_runs_ids)].sort_values(by=['run', 'utcTime'])\n",
    "\n",
    "# Create a LineString object representing the entire route from the first two runs\n",
    "route_points = first_two_runs.geometry.tolist()\n",
    "route_line = LineString(route_points)\n",
    "\n",
    "# Convert the LineString to a GeoDataFrame\n",
    "route_line_gdf = gpd.GeoDataFrame(\n",
    "    {'geometry': [route_line]},\n",
    "    crs=runs.crs\n",
    ")\n",
    "\n",
    "# Define the stop line to work with\n",
    "stop_line_name = 'GoethestraÃŸe'  # Replace with the actual stop line name\n",
    "stop_line = stop_lines[stop_lines['Stop Name'] == stop_line_name].iloc[0]\n",
    "stop_line_point = stop_line.geometry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate distance between two points on the bus route\n",
    "def calculate_route_distance(route_line, point1, point2):\n",
    "   \n",
    "    try:\n",
    "        # Project points onto the route line\n",
    "        projection1 = route_line.project(point1)\n",
    "        projection2 = route_line.project(point2)\n",
    "        \n",
    "        if np.isnan(projection1) or np.isnan(projection2):\n",
    "            print(f\"Invalid projection values: projection1={projection1}, projection2={projection2}, point1={point1}, point2={point2}\")\n",
    "            return None\n",
    "\n",
    "        # Ensure the projections are within bounds\n",
    "        projection1 = max(0, min(projection1, route_line.length))\n",
    "        projection2 = max(0, min(projection2, route_line.length))\n",
    "\n",
    "        projected_point1 = route_line.interpolate(projection1)\n",
    "        projected_point2 = route_line.interpolate(projection2)\n",
    "        \n",
    "        # Check if projected points are valid\n",
    "        if not isinstance(projected_point1, Point) or not isinstance(projected_point2, Point):\n",
    "            print(f\"Invalid projected points: projected_point1={projected_point1}, projected_point2={projected_point2}, point1={point1}, point2={point2}\")\n",
    "            return None\n",
    "        \n",
    "        # Create a LineString between the two projected points\n",
    "        segment = LineString([projected_point1, projected_point2])\n",
    "        \n",
    "        # Calculate the distance\n",
    "        distance = segment.length\n",
    "        return distance\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating route distance: {e}, point1={point1}, point2={point2}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for models\n",
    "data = []\n",
    "\n",
    "# Iterate through each run\n",
    "for run_id, run in runs.groupby('run'):\n",
    "    run = run.sort_values(by='utcTime').reset_index(drop=True)\n",
    "    \n",
    "    # Check if the run duration is less than 3 minutes\n",
    "    run_start_time = run.loc[0, 'utcTime']\n",
    "    run_end_time = run.loc[len(run) - 1, 'utcTime']\n",
    "    run_duration = (run_end_time - run_start_time).total_seconds()\n",
    "    if run_duration >= 1.86 * 60:\n",
    "        continue  # Skip this run if duration is more than or equal to 3 minutes\n",
    "    \n",
    "\n",
    "    nearest_stop_point, _ = nearest_points(run.geometry.unary_union, stop_line_point)\n",
    "    nearest_stop_idx = run.index[run.geometry == nearest_stop_point][0]\n",
    "    nearest_stop_time = run.loc[nearest_stop_idx, 'utcTime']\n",
    "    \n",
    "    for i, row in run.iterrows():\n",
    "        current_point = row.geometry\n",
    "        current_time = row.utcTime\n",
    "        \n",
    "        if i >= nearest_stop_idx:\n",
    "            continue\n",
    "        \n",
    "        distance = calculate_route_distance(route_line_gdf.geometry.iloc[0], current_point, stop_line_point)\n",
    "        \n",
    "        if distance is None:\n",
    "            continue\n",
    "        \n",
    "        time_difference = (nearest_stop_time - current_time).total_seconds()\n",
    "        if time_difference < 0:\n",
    "            continue\n",
    "        \n",
    "        day_of_week = current_time.weekday()\n",
    "        time_of_day = current_time.hour\n",
    "        month_of_year = current_time.month\n",
    "        year_week = current_time.strftime('%Y-%U')\n",
    "\n",
    "        data.append([run_id, distance, day_of_week, time_of_day, month_of_year, time_difference, year_week])\n",
    "\n",
    "print(len(data))\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data, columns=['run', 'distance', 'day_of_week', 'time_of_day', 'month_of_year', 'time_difference', 'year_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique weeks\n",
    "unique_weeks = df['year_week'].unique()\n",
    "\n",
    "# Split weeks into training and testing sets (80% training, 20% testing)\n",
    "train_weeks, test_weeks = train_test_split(unique_weeks, test_size=0.2, random_state=42)\n",
    "\n",
    "# Assign data to training and testing sets based on the week split\n",
    "train_df = df[df['year_week'].isin(train_weeks)]\n",
    "test_df = df[df['year_week'].isin(test_weeks)]\n",
    "\n",
    "# Prepare features (X) and target (y) for training and testing sets\n",
    "X_train = train_df[['distance', 'day_of_week', 'time_of_day', 'month_of_year']]\n",
    "y_train = train_df['time_difference']\n",
    "X_test = test_df[['distance', 'day_of_week', 'time_of_day', 'month_of_year']]\n",
    "y_test = test_df['time_difference']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape X for LSTM (samples, time steps, features)\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(16, activation='tanh', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "log_dir = \"logs/fit/LSTM_without_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "\n",
    "# Train the LSTM model\n",
    "history = model.fit(X_train_reshaped, y_train, epochs=20, batch_size=64, validation_data=(X_test_reshaped, y_test), verbose=1, callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_lstm = model.predict(X_test_reshaped)\n",
    "mse_lstm = mean_squared_error(y_test, y_pred_lstm)\n",
    "rmse_lstm = np.sqrt(mse_lstm)\n",
    "r2_lstm = r2_score(y_test, y_pred_lstm)\n",
    "\n",
    "print(f'LSTM Model - RMSE: {rmse_lstm}, R-squared: {r2_lstm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f'MLP Model - RMSE: {rmse_lstm}, R-squared: {r2_lstm}')\n",
    "\n",
    "# Get training and validation loss\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "training_mae = history.history['mae']\n",
    "validation_mae = history.history['val_mae']\n",
    "\n",
    "print(f'MLP Model - Final Training Loss: {training_loss[-1]}')\n",
    "print(f'MLP Model - Final Validation Loss: {validation_loss[-1]}')\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(training_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation MAE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(training_mae, label='Training MAE')\n",
    "plt.plot(validation_mae, label='Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot predicted vs actual values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_test, y_pred_lstm, alpha=0.01)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Predicted vs Actual Values')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')  # Diagonal line for reference\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict time difference using the trained LSTM model\n",
    "def predict_time_difference_lstm(current_location, current_time):\n",
    "    if isinstance(current_location, tuple):\n",
    "        current_location = Point(current_location)\n",
    "    \n",
    "    distance = calculate_route_distance(route_line_gdf.geometry.iloc[0], current_location, stop_line_point)\n",
    "\n",
    "    day_of_week = current_time.weekday()\n",
    "    time_of_day = current_time.hour + current_time.minute / 60.0\n",
    "    month_of_year = current_time.month\n",
    "    \n",
    "    \n",
    "    features = pd.DataFrame([[distance, day_of_week, time_of_day, month_of_year]], columns=['distance', 'day_of_week', 'time_of_day', 'month_of_year'])\n",
    "    features_scaled = scaler.transform(features)\n",
    "    features_reshaped = features_scaled.reshape((features_scaled.shape[0], 1, features_scaled.shape[1]))\n",
    "    predicted_time_difference = model.predict(features_reshaped)\n",
    "    \n",
    "    if predicted_time_difference.ndim == 1:\n",
    "        return predicted_time_difference[0]\n",
    "    return predicted_time_difference.item()\n",
    "\n",
    "current_location = (679646.0070022508, 5405541.164896245)  # Example UTM coordinates (meters)\n",
    "current_time = datetime(2024, 6, 10, 10, 35, 45)\n",
    "print(current_time)\n",
    "predicted_time = predict_time_difference_lstm(current_location, current_time)\n",
    "print(f'Predicted Time Difference in Seconds: {predicted_time}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bus_eta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
